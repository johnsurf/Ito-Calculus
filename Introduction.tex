\section{Introduction}
\label{sec:Introduction}
A stochastic process $\{ X(t), t \in T\}$ is a parameterized collection of random variables. That is, for each $t\in T, X(t)$ is a random variable. The set $T$ is the {\elevenit parameter space} or {\elevenit index set} of the process and contains the allowed values of $t$. An index set $T$ is said to be a {\elevenit linear} index set if it has the property that the sum $t+h$, of any two members $t$ and $h$ of $T$, also belongs to $T$. If $t$ is {\elevenit time}, we can call the stochastic process a {\elevenit time series}.  Many results in stochastic processes are for time series -- where observations are made over a period of time for particular random quantities, e.g. the observation of the whole time history of the temperature at a particular location every hour for a year. \\

$X(t)$ represents the {\elevenit state}\/ of the process at time $t$. When $T$ is countable, then the stochastic process is said to be a {\elevenit discrete-time} process. If $T$ is an interval of the real line, the stochastic process is said to be a {\elevenit continuous-time}\/ process. Discrete-time processes can be represented as $\{X_n, n = 1, 2, ...\}$; while continuous-time processes can be represented as $\{ X(t), t\ge0\}$.\\

Statistical problems generally work with a sample chosen from a given set of elementary outcomes that can be selected from a larger space which is denoted by $\Omega$. $\Omega$ is the universe of possible outcomes and is called the {\elevenit sample space}. The elementary outcomes contained in $\Omega$ are labeled $\omega$. Possible sets of outcomes are referred to as {\elevenit events}. If $A$ is an event, then $A$ consists of a set of possible outcomes and is itself a subset contained in $\Omega: A \subset \Omega$.  With time series, each elementary outcome represents an entire set of random variables, e.g.,  $\{ X(t), t \in T\}$. We will use the notation $\{ X(t, \omega), t\in T, \omega \in \Omega \}$, or the shorter version $\{ X(t), t\in T\}$ where is is understood that $\{ X(t), t\in T\}$  corresponds to a single value of $\omega$.\\

In experimental practice, it is possible to vary the length of the observed time series by changing the time interval $T$, however it is usually impossible to observe more than one time series at a time. So we end up with a single outcome of the stochastic process and a single observation of the random variable of interest at time $t$. We view the observed time series as one outcome in a much larger sample space (denoted as $\Omega$ which could have an infinity of possible outcomes). The particular observed time series is said to be a {\elevenit realization} of the stochastic process. Here one outcome in the sample space is a single and entire sample function defined on the whole interval $T$.\\

The theory of stochastic processes can be viewed as the dynamical part of probability theory.\\ 

We will study probability and stochastic processes using various concepts such as {\elevenit mean squared  convergence}\/ which is simpler than other kinds of convergence summarized in Section [\ref{sec:convergence}].  We will be concerned in these notes with the properties of a particular stochastic process: The Wiener Process or Brownian Motion. An important fact is that there are different ways to work with stochastic processes, each with varying degrees of difficulty and with different degrees of completeness. {\elevenit Ordinary}\/ calculus is too restrictive because it requires the results to hold for {\elevenit every} possible sample function. For most cases of interest, it is not necessary for a result to hold for all sample functions -- but to hold for {\elevenit almost all}\/ sample functions. Therefore a less restrictive approach than using ordinary calculus is to ignore those sample functions belonging sets in the sample space with probability zero (probability zero is the same as measure zero). If results are required to converge at the individual sample function level (one complete sample function at a time) with probability one (wp1), then the tools require some sophistication in the methods used such as Lebesgue measure theory. \\ 

Many results in stochastic processes  are not required to hold wp1 at the sample function level -- but only to hold {\elevenit on average}\/ for the most important cases which influence the statistical averages. This is the motivation for using {\elevenit mean-squared calculus}\/ --  it discards the difficulties involved with dealing wp1 at the sample function level and works only with the {\elevenit important}\/ sample functions that affect the statistical averages -- which covers most of the cases of interest in applications. In a nut shell, what mean-squared calculus has too offer is {\elevenit simplicity}. We will occasionally work with results at the sample function level -- such as the quadratic and total variation properties of the Brownian paths as well as the Kolmogorov continuity theorem. We will make comparisons occasionally between the mean-squared and the sample-function-level approaches.